\documentclass{article}
\usepackage[final]{neurips_2024} 

\usepackage[utf8]{inputenc}   
\usepackage[T1]{fontenc}      
\usepackage{amsmath, amssymb} 
\usepackage{graphicx}         
\usepackage{booktabs}    
\usepackage{amsthm} % Theorem environments
\newtheorem{proposition}{Proposition}

\title{On the Preservation of Decision Boundaries and Out-of-Distribution Uncertainty in Laplace-Approximated Neural Networks}
\author{%
  First Author \\
  Institution \\
  \texttt{first.author@example.com}
  \and
  Second Author \\
  Institution \\
  \texttt{second.author@example.com}
}

\begin{document}
\maketitle

\section{Introduction and Overview}

Neural networks have demonstrated remarkable success in a wide range of tasks, yet they are prone to producing overconfident predictions, particularly when faced with out-of-distribution (OOD) inputs. This overconfidence is problematic in safety-critical applications, such as medical diagnosis and autonomous driving, where uncertainty quantification is crucial for making reliable decisions.

Bayesian deep learning methods have been proposed as a solution to this issue, incorporating uncertainty estimation into neural network predictions. Among these approaches, the Laplace Approximation for Last-Layer Approximation (LLLA)\cite{main_paper} has emerged as an efficient and scalable method for introducing Bayesian uncertainty. LLLA approximates the posterior distribution over network weights with a Gaussian distribution centered at the maximum a posteriori (MAP) estimate, with the covariance given by the inverse Hessian of the loss function. This approach allows for calibrated uncertainty estimation while maintaining computational efficiency, making it particularly suitable for large-scale deep learning models.

\subsection{Summary of the Paper \emph{"Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks"}}

\cite{main_paper} systematically investigates how Bayesian approximations, specifically the Laplace approximation, can mitigate the overconfidence problem in deep ReLU networks. The paper presents several key theoretical and empirical contributions:

\begin{itemize}
    \item \textbf{Laplace Approximation for Uncertainty Estimation:} 
    The authors propose applying the Laplace approximation specifically to the last layer of a neural network (LLLA) to approximate the posterior over network weights. This provides a principled and computationally efficient method for uncertainty estimation.
    
    \item \textbf{Probit Approximation for Confidence Bounds:} 
    By approximating the logistic sigmoid function with a Gaussian probit function, they derive an upper bound on predictive confidence. This theoretical result establishes that LLLA can effectively control overconfidence in binary classification settings.

    \item \textbf{Empirical Validation:} 
    The authors conduct extensive experiments on benchmark datasets such as MNIST and CIFAR-10. Their results demonstrate that LLLA significantly reduces overconfidence compared to standard neural networks, ensuring that predictive confidence remains bounded even for OOD inputs.
\end{itemize}

\subsection{Limitations and Contributions}

Despite its advantages, several open questions remain regarding the theoretical properties and practical implications of LLLA, particularly in the multi-class classification setting. While \cite{main_paper} establishes the effectiveness of LLLA using a probit approximation in the binary case and applies this approximation in practice, for multi-class classification, the authors instead resort to Monte Carlo estimation to approximate the intractable expectation. This raises uncertainty about whether the theoretical guarantees derived from the probit approximation extend to the multi-class setting.

In this work, we analyze the theoretical validity of LLLA in mitigating overconfidence for OOD inputs by reframing the multi-class problem as a set of binary classification problems. Additionally, we investigate the preservation of decision boundaries in multi-class settings, providing further insight into the structural properties of LLLA.



\section{Extension of Theoretical Results to Multiclass}
While \cite{main_paper} provides strong theoretical results proving the effectiveness of LLLA in reducing overconfidence in out-of-distribution (OOD) regions, these results have not been extended to the multi-class classification setting.

This limitation arises because the integral for the softmax function
\begin{equation}
\label{softmax_integration}
    p(y=k | x, \mathcal{D}) = \int \text{softmax}(f_{\theta, k}(x)) 
    \mathcal{N}(f_{\theta, k}(x) | f_{\mu, k}(x), \Sigma_k) df_{\theta, k}(x)
\end{equation}
has no simple closed-form solution or standard approximation. As a result, the authors of \cite{main_paper} resort to Monte Carlo approximation when applying LLLA to the multi-class setting.

In this work, we instead apply a probit approximation to the softmax function and justify the ability of LLLA to regularize overconfidence through the following result.

\begin{proposition}
Let \( f_{\theta,k}(x) \) be the output of a ReLU network with weights \( \theta \) and input \( x \), and let \( f_{\mu,k}(x) \) be the mean function under the Laplace approximation at \( \theta = \mu \). Assume that the posterior covariance \( \Sigma_k \) is given by the Hessian approximation of the log-posterior. Then, for sufficiently large input magnitude \( \delta \), the predictive probability satisfies
\begin{equation}
    \lim_{\delta\to \infty} \lvert z_k(\delta x)\rvert \leq 
    \sigma \left(\frac{\lVert\mathbf{u}_k\rVert}{s_{\min}(\tilde{J})\sqrt{\frac{\pi}{8}\lambda_{\min}(\Sigma)}}\right),
\end{equation}
where \( s_{\min}(\tilde{J}) := \min_{l} s_{\min}(J_{l}) \) and \( J_{\text{eff}} = J_k + \sum_{j \neq k} w_j J_j \) is the effective Jacobian.
\end{proposition}

\begin{proof}
We outline the key ideas of the proof below.

First, note that for all \( k \in [K] \), the softmax function can be rewritten as:
\begin{equation}
    \text{softmax}(f_{\theta,k}(x)) = \sigma(\tilde{f}_{\theta,k}(x)),
\end{equation}
where
\begin{equation}
    \tilde{f}_{\theta,k}(x) = f_{\theta,k}(x) + \log \sum_{j\neq k} \exp(f_{\theta, j}(x)).
\end{equation}
Applying the probit approximation for the sigmoid function, \( \sigma(a) \approx \Phi(\frac{\pi}{8}a) \), we obtain an approximation for 
\begin{equation}
    \label{zk_definition}
    z_k(x) := \frac{\tilde{f}_{\mu,k}(x)}{\sqrt{1+\frac{\pi}{8}d_k^{\intercal}\Sigma d_k}}
\end{equation}

\begin{equation}
    \label{softmax_approx}
    p (y = k | x, \mathcal{D}) \approx \sigma\left(z_k(x)\right),
\end{equation}

where \( d_k = \nabla_{\theta} \tilde{f}_{\theta,k}(x)|_{\mu} \).

To show that \( x \) cancels out in the numerator and denominator, we again consider the piecewise linearity of ReLU. For all \( k \in [K] \), we can write:
\begin{equation}
    f_{\theta,k}(x) = \mathbf{u}_{k}^{\intercal}x + b_{k}.
\end{equation}
Thus, the gradient \( d_k \) at \( \delta x \) for any \( \delta \) can be written as
\begin{align*}
    d_{k}(\delta x) =
    &\delta (J_{k}^{\intercal}x + \frac{1}{\delta}\nabla_{\theta} b_{k}|_{\mu}) 
    + \sum_{j\neq k}\delta w_{j}(J_{j}^{\intercal}x + \frac{1}{\delta}\nabla_{\theta}b_{j}|_{\mu})\\
    & := \delta J_{\text{eff}}^{\intercal}x + \nabla_{\theta} b_{\text{eff}}|_{\mu}.
\end{align*}
where
\begin{align*}
    & J_l = \frac{\partial \mathbf{u}_{l}}{\partial \theta}|_{\mu}, \quad \forall l \in [K],\\
    & w_j = \frac{\exp(f_{\mu,j}(x))}{\sum_{l\neq k}\exp(f_{\mu, l}(x))}, \quad \forall j \neq k, \\
    & J_{\text{eff}} = J_{k} + \sum_{j \neq k}w_j J_j, \\
    & b_{\text{eff}} = b_{k} + \sum_{j \neq k}w_j b_{j}.
\end{align*}
By a similar argument as in \cite{main_paper}, we obtain
\begin{equation*}
    \lim_{\delta\to \infty} \lvert z(\delta x)\rvert \leq \frac{\lVert\mathbf{u}_k\rVert \lVert x\rVert}
    {\sqrt{\frac{\pi}{8}\lambda_{\min}(\Sigma) \lVert J_{\text{eff}}^{\intercal}x}\rVert^{2}}.
\end{equation*}
Noting that \( s_{\min}(\tilde{J}) := \min_{l} s_{\min}(J_{l}) \leq s_{\min}(J_{\text{eff}}) \), we therefore conclude
\begin{equation*}
    \lim_{\delta\to \infty} \lvert z(\delta x)\rvert \leq 
    \sigma \left(\frac{\lVert\mathbf{u}_k\rVert}{s_{\min}(\tilde{J})\sqrt{\frac{\pi}{8}\lambda_{\min}(\Sigma)}}\right).
\end{equation*}
\end{proof}

The above result has been demonstrated for Full Laplace, but a similar approach can be applied to Last-Layer Laplace as well.

The key idea behind this proof is that, although we are analyzing \(K\) classes, our primary concern is ensuring that the predicted probability for any given class does not exhibit overconfidence. This allows us to reframe the problem as a binary classification task, where we distinguish between a sample being classified as class \(k\) versus not being classified as class \(k\). Moreover, while transforming softmax into sigmoid introduces non-linearity, we can circumvent this issue by leveraging the bounded nature of the softmax function.

Thus, under an appropriate approximation, we confirm that for any class in a multi-class classification setting, the overconfidence of OOD samples can be controlled. Of course, as in the binary case, one may consider using this approximation \(z_k\) in practice. However, unlike the binary setting, the denominator in \(z_k\) now depends on the gradient of the transformed ReLU output, \( \tilde{f}_{\theta, k} \). This dependence disrupts decision boundary preservation, leading to the discussion in the next section.

Additionally, since this approximation is based on treating each class as an independent binary classification task, directly applying it to a multi-class setting may lead to over-regularization, where the predicted probabilities become overly smoothed.


\section{Softmax-Based Predictive Probability and Decision Boundary Preservation}

\subsection{Full-Laplace Does Not Preserve Decision Boundaries}

We claim that Full Laplace Approximation does not preserve decision boundaries in multi-class classification due to class-dependent uncertainty.

To see why, consider the second-order Taylor expansion of the softmax function:

\begin{equation}
    p(y=k | x, \mathcal{D}) = \mathbb{E} \left[ \operatorname{softmax}(f_{\theta, k}(x)) \right] \approx \frac{e^{f_{\mu,k}(x) + \frac{1}{2} \sigma_k^2(x)}}{\sum_{j=1}^{K} e^{f_{\mu,j}(x) + \frac{1}{2} \sigma_j^2(x)}},
\end{equation}
where the marginal variance of the logit \( f_{\theta,k}(x) \) is given by

\begin{equation}
    \sigma_k^2(x) = d_k(x)^T \Sigma d_k(x),
\end{equation}
with \( d_k(x) = \nabla_{\theta} f_{\theta,k}(x) \) being the Jacobian of the logit with respect to all network parameters, and \( \Sigma \) being the Laplace-approximated posterior covariance.

A decision boundary between classes \( k \) and \( j \) is classically defined as

\begin{equation}
    f_{\mu,k}(x) = f_{\mu,j}(x).
\end{equation}

Under the uncertainty-aware softmax approximation, since \( \sigma_k^2(x) \) varies across classes, the decision boundary is now implicitly determined by

\begin{equation}
    f_{\mu,k}(x) + \frac{1}{2} \sigma_k^2(x) = f_{\mu,j}(x) + \frac{1}{2} \sigma_j^2(x).
\end{equation}

This equation implies that the decision boundary shifts whenever \( \sigma_k^2(x) \neq \sigma_j^2(x) \). In Full Laplace, this occurs because the uncertainty term \( \sigma_k^2(x) \) depends on \( d_k(x) \), which is the gradient of the logit with respect to the entire set of network parameters. 

In a deep network with multiple layers, the logit function for class \( k \) depends on parameters from all layers,

\begin{equation}
    f_k(x) = f_k(W_L, W_{L-1}, \dots, W_1, x).
\end{equation}

Taking the gradient with respect to all parameters, we obtain

\begin{equation}
    d_k(x) = \left[ \frac{\partial f_k}{\partial W_L}, \frac{\partial f_k}{\partial W_{L-1}}, \dots, \frac{\partial f_k}{\partial W_1} \right].
\end{equation}

Since different classes \( k \) and \( j \) are associated with different weight paths through the network, their gradients are not identical, meaning

\begin{equation}
    d_k(x) \neq d_j(x).
\end{equation}

As a result, the uncertainty estimates \( \sigma_k^2(x) \) vary across classes, causing shifts in the decision boundary.

Although this argument may not be the most rigorous way to establish decision boundary preservation, it provides valuable intuition. The variance term contributes to the posterior predictive probability in a structured manner, and any class-dependent variation in uncertainty inevitably affects the decision boundary when considering the true expectation. A similar issue arises in the binary classification case: if one directly computes the Monte Carlo expectation of the sigmoid function instead of using the probit approximation, the decision boundary is no longer preserved. This highlights a key insight—decision boundary preservation is not an inherent property of LLLA itself, but rather a consequence of how uncertainty is modeled. In fact, the remarkable aspect of the LLLA formulation is that in the binary case, the authors identified an approximation that enforces decision boundary preservation while simultaneously regularizing confidence via prior variance.

\subsection{Last-Layer Laplace Approximation Preserves Decision Boundaries}

In contrast to Full Laplace, Last-Layer Laplace Approximation (LLLA) might preserves decision boundaries because the uncertainty term is the same for all classes. The final layer of a neural network follows a linear structure,

\begin{equation}
    f_k(x) = u_k^T \phi(x),
\end{equation}
where \( u_k \) is the last-layer weight vector for class \( k \) and \( \phi(x) \) is the feature embedding. Since LLLA only approximates uncertainty over the last-layer weights, the gradient with respect to the last-layer parameters is given by

\begin{equation}
    d_k(x) = \nabla_{\theta} f_k(x) = \phi(x).
\end{equation}

Following a similar argument as in the previous section, this demonstrates that LLLA preserves decision boundaries, albeit in a somewhat ad-hoc manner. Unlike Full Laplace, where different classes exhibit varying uncertainty contributions from earlier layers, LLLA enforces a shared uncertainty structure across all logits, ensuring that the decision boundary remains unchanged.

This observation aligns with broader discussions in the literature that suggest Last-Layer Bayesian approximations are often preferable to full Bayesian models in deep learning. Several works \cite{ritter2018scalable, kristiadi2020being} argue that last-layer approximations strike a favorable balance between:
\begin{itemize}
    \item Computational efficiency (avoiding full weight-space posterior estimation).
    \item Well-calibrated uncertainty (capturing model confidence without excessive complexity).
    \item Decision boundary preservation (ensuring that uncertainty modeling does not distort classification regions).
\end{itemize}

This suggests that LLLA is not just computationally practical but also structurally advantageous in maintaining stable decision boundaries while incorporating uncertainty.





\begin{thebibliography}{9}
\bibitem{main_paper}
A. Kristiadi, M. Hein, and P. Hennig.
\newblock Being Bayesian, even just a bit, fixes overconfidence in ReLU networks.
\newblock arXiv preprint arXiv:2002.10118, 2020.
\newblock URL: \url{https://arxiv.org/abs/2002.10118}.

\bibitem{ritter2018scalable}
Hippolyt Ritter, Aleksandar Botev, and David Barber.
\newblock A scalable Laplace approximation for neural networks.
\newblock In \emph{6th International Conference on Learning Representations (ICLR 2018)}, Vancouver, Canada, 2018.

\bibitem{kristiadi2020being}
Agustinus Kristiadi, Matthias Hein, and Philipp Hennig.
\newblock Being Bayesian, even just a bit, fixes overconfidence in ReLU networks.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning (ICML 2020)}, Vienna, Austria, 2020.

\end{thebibliography}

\end{document}